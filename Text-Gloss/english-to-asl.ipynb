{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5117745,"sourceType":"datasetVersion","datasetId":2972312},{"sourceId":5121773,"sourceType":"datasetVersion","datasetId":2974764},{"sourceId":5122082,"sourceType":"datasetVersion","datasetId":2974977},{"sourceId":5122811,"sourceType":"datasetVersion","datasetId":2975461},{"sourceId":11050947,"sourceType":"datasetVersion","datasetId":6884613}],"dockerImageVersionId":30370,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Encoder Decoder ","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom datasets import load_dataset\nfrom sklearn.utils import shuffle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T14:44:01.343577Z","iopub.execute_input":"2025-03-16T14:44:01.343964Z","iopub.status.idle":"2025-03-16T14:44:02.363071Z","shell.execute_reply.started":"2025-03-16T14:44:01.343869Z","shell.execute_reply":"2025-03-16T14:44:02.362092Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Importing Data","metadata":{}},{"cell_type":"code","source":"#df = pd.read_csv('ASL_English.csv')\ndf = pd.read_csv('/kaggle/input/english-gloss-dataset/train.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:49:54.237074Z","iopub.execute_input":"2025-03-16T15:49:54.237411Z","iopub.status.idle":"2025-03-16T15:49:54.444545Z","shell.execute_reply.started":"2025-03-16T15:49:54.237385Z","shell.execute_reply":"2025-03-16T15:49:54.443658Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"                                            gloss  \\\n0             ﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n1  APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n   \n2              MEMBERSHIP PARLIAMENT SEE MINUTE\\n   \n3           VERIFICATION CREDENTIALS SEE MINUTE\\n   \n4                   DOCUMENT RECEIVE SEE MINUTE\\n   \n\n                                                text  \n0            ﻿membership of parliament see minutes\\n  \n1  approval of minutes of previous sitting see mi...  \n2             membership of parliament see minutes\\n  \n3          verification of credentials see minutes\\n  \n4                   documents received see minutes\\n  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gloss</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>﻿MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n      <td>﻿membership of parliament see minutes\\n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>APPROVAL MINUTE DESC-PREVIOUS SIT SEE MINUTE\\n</td>\n      <td>approval of minutes of previous sitting see mi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MEMBERSHIP PARLIAMENT SEE MINUTE\\n</td>\n      <td>membership of parliament see minutes\\n</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>VERIFICATION CREDENTIALS SEE MINUTE\\n</td>\n      <td>verification of credentials see minutes\\n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DOCUMENT RECEIVE SEE MINUTE\\n</td>\n      <td>documents received see minutes\\n</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:49:58.177054Z","iopub.execute_input":"2025-03-16T15:49:58.177379Z","iopub.status.idle":"2025-03-16T15:49:58.183834Z","shell.execute_reply.started":"2025-03-16T15:49:58.177351Z","shell.execute_reply":"2025-03-16T15:49:58.182970Z"},"trusted":true},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"(87710, 2)"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"### Preprocessing\n\nNote:\n- Replace the numbers/digits\n- Check regarding Finger spellings\n- Check if it is required to add start and end tokens to target sequences","metadata":{}},{"cell_type":"code","source":"replacements = {'1': \" one \", '2': \" two \", '3': \" three \", '4': \" four \", \n                '5': \" five \", '6': \" six \", '7': \" seven \", '8': \" eight \", \n                '9': \" nine \", '0': \" zero \"}\n\n# Apply number replacement to text (English input)\ndf['text'] = df['text'].apply(lambda x: re.sub(r'(\\d)', lambda m: replacements[m.group()], x))\n\n# Apply number replacement to gloss (ASL output)\ndf['gloss'] = df['gloss'].apply(lambda x: re.sub(r'(\\d)', lambda m: replacements[m.group()], x))\n\ndf['gloss'] = df['gloss'].apply(lambda x: re.sub(r'\\s*\\(wh\\)\\s*', ' ', x))\n\n# Remove extra spaces\ndf['text'] = df['text'].apply(lambda x: x.strip())\ndf['gloss'] = df['gloss'].apply(lambda x: x.strip())\n\n# Convert to lowercase\ndf['text'] = df['text'].apply(lambda x: x.lower())\ndf['gloss'] = df['gloss'].apply(lambda x: x.lower())\n\n# Remove double spaces\ndf['text'] = df['text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\ndf['gloss'] = df['gloss'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n\n# Remove punctuation\ndf['text'] = df['text'].apply(lambda x: ''.join(ch for ch in x if ch not in string.punctuation))\ndf['gloss'] = df['gloss'].apply(lambda x: ''.join(ch for ch in x if ch not in string.punctuation))\n\n# **Fix: Properly remove \"(wh)\" from gloss**\n\n\n# Remove any additional double spaces left after removal\ndf['gloss'] = df['gloss'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n\n# Add tokens to gloss (since it's now the target output)\ndf['gloss'] = df['gloss'].apply(lambda x: 'START_ ' + x.strip() + ' _END')","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:01.320798Z","iopub.execute_input":"2025-03-16T15:50:01.321485Z","iopub.status.idle":"2025-03-16T15:50:04.486504Z","shell.execute_reply.started":"2025-03-16T15:50:01.321451Z","shell.execute_reply":"2025-03-16T15:50:04.485525Z"},"trusted":true},"outputs":[],"execution_count":61},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:07.897824Z","iopub.execute_input":"2025-03-16T15:50:07.898450Z","iopub.status.idle":"2025-03-16T15:50:07.907446Z","shell.execute_reply.started":"2025-03-16T15:50:07.898417Z","shell.execute_reply":"2025-03-16T15:50:07.906497Z"},"trusted":true},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                               gloss  \\\n0      START_ ﻿membership parliament see minute _END   \n1  START_ approval minute descprevious sit see mi...   \n2       START_ membership parliament see minute _END   \n3    START_ verification credentials see minute _END   \n4            START_ document receive see minute _END   \n5  START_ write statement and descoral question t...   \n6                    START_ petition see minute _END   \n7  START_ text agreement descforward by council s...   \n8  START_ action take on parliament xposs resolut...   \n9         START_ agenda for next sit see minute _END   \n\n                                                text  \n0              ﻿membership of parliament see minutes  \n1  approval of minutes of previous sitting see mi...  \n2               membership of parliament see minutes  \n3            verification of credentials see minutes  \n4                     documents received see minutes  \n5  written statements and oral questions tabling ...  \n6                              petitions see minutes  \n7  texts of agreements forwarded by the council s...  \n8  action taken on parliaments resolutions see mi...  \n9                agenda for next sitting see minutes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gloss</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>START_ ﻿membership parliament see minute _END</td>\n      <td>﻿membership of parliament see minutes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>START_ approval minute descprevious sit see mi...</td>\n      <td>approval of minutes of previous sitting see mi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>START_ membership parliament see minute _END</td>\n      <td>membership of parliament see minutes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>START_ verification credentials see minute _END</td>\n      <td>verification of credentials see minutes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>START_ document receive see minute _END</td>\n      <td>documents received see minutes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>START_ write statement and descoral question t...</td>\n      <td>written statements and oral questions tabling ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>START_ petition see minute _END</td>\n      <td>petitions see minutes</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>START_ text agreement descforward by council s...</td>\n      <td>texts of agreements forwarded by the council s...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>START_ action take on parliament xposs resolut...</td>\n      <td>action taken on parliaments resolutions see mi...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>START_ agenda for next sit see minute _END</td>\n      <td>agenda for next sitting see minutes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"df.tail(10)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:11.192536Z","iopub.execute_input":"2025-03-16T15:50:11.193242Z","iopub.status.idle":"2025-03-16T15:50:11.202252Z","shell.execute_reply.started":"2025-03-16T15:50:11.193208Z","shell.execute_reply":"2025-03-16T15:50:11.201189Z"},"trusted":true},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                                                   gloss  \\\n87700            START_ document receive see minute _END   \n87701  START_ write declaration include in register r...   \n87702  START_ forwarding text adopt during sit see mi...   \n87703    START_ date descforthcoming sit see minute _END   \n87704                          START_ name you what _END   \n87705                          START_ name you what _END   \n87706                          START_ name you what _END   \n87707                          START_ name you what _END   \n87708                              START_ eat apple _END   \n87709                             START_ eat orange _END   \n\n                                                    text  \n87700                     documents received see minutes  \n87701  written declarations included in the register ...  \n87702  forwarding of texts adopted during the sitting...  \n87703          dates of forthcoming sittings see minutes  \n87704                                  what is your name  \n87705                                 what is your name   \n87706                                    whats your name  \n87707                                   whats your name   \n87708                                     i eat an apple  \n87709                                    i eat an orange  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gloss</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>87700</th>\n      <td>START_ document receive see minute _END</td>\n      <td>documents received see minutes</td>\n    </tr>\n    <tr>\n      <th>87701</th>\n      <td>START_ write declaration include in register r...</td>\n      <td>written declarations included in the register ...</td>\n    </tr>\n    <tr>\n      <th>87702</th>\n      <td>START_ forwarding text adopt during sit see mi...</td>\n      <td>forwarding of texts adopted during the sitting...</td>\n    </tr>\n    <tr>\n      <th>87703</th>\n      <td>START_ date descforthcoming sit see minute _END</td>\n      <td>dates of forthcoming sittings see minutes</td>\n    </tr>\n    <tr>\n      <th>87704</th>\n      <td>START_ name you what _END</td>\n      <td>what is your name</td>\n    </tr>\n    <tr>\n      <th>87705</th>\n      <td>START_ name you what _END</td>\n      <td>what is your name</td>\n    </tr>\n    <tr>\n      <th>87706</th>\n      <td>START_ name you what _END</td>\n      <td>whats your name</td>\n    </tr>\n    <tr>\n      <th>87707</th>\n      <td>START_ name you what _END</td>\n      <td>whats your name</td>\n    </tr>\n    <tr>\n      <th>87708</th>\n      <td>START_ eat apple _END</td>\n      <td>i eat an apple</td>\n    </tr>\n    <tr>\n      <th>87709</th>\n      <td>START_ eat orange _END</td>\n      <td>i eat an orange</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"# df['ASL Gloss'].str.len().sort_values(ascending=False).head()\n# df['English'].str.len().sort_values(ascending=False).head()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:57:33.125858Z","iopub.execute_input":"2023-03-08T10:57:33.126649Z","iopub.status.idle":"2023-03-08T10:57:33.13472Z","shell.execute_reply.started":"2023-03-08T10:57:33.126608Z","shell.execute_reply":"2023-03-08T10:57:33.133775Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vocabulary of English (text column)\nall_eng_words = set()\nfor eng in df['text']:\n    for word in eng.split():\n        all_eng_words.add(word)\n\n# Vocabulary of ASL (gloss column)\nall_ASL_words = set()\nfor asl in df['gloss']:\n    for word in asl.split():\n        all_ASL_words.add(word)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:16.745126Z","iopub.execute_input":"2025-03-16T15:50:16.745995Z","iopub.status.idle":"2025-03-16T15:50:17.190269Z","shell.execute_reply.started":"2025-03-16T15:50:16.745958Z","shell.execute_reply":"2025-03-16T15:50:17.189275Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Compute max length for English (source) text\nlength_list = [len(sentence.split()) for sentence in df['text']]  # English as input\nmax_length_src = np.max(length_list)  \nprint(\"Max length source (English):\", max_length_src)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:19.423472Z","iopub.execute_input":"2025-03-16T15:50:19.424332Z","iopub.status.idle":"2025-03-16T15:50:19.504329Z","shell.execute_reply.started":"2025-03-16T15:50:19.424296Z","shell.execute_reply":"2025-03-16T15:50:19.503479Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Max length source (English): 64\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Compute max length for ASL Gloss (target)\nlength_list = [len(sentence.split()) for sentence in df['gloss']]  # ASL Gloss as output\nmax_length_tar = np.max(length_list)  \nprint(\"Max length target (ASL Gloss):\", max_length_tar)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:21.217108Z","iopub.execute_input":"2025-03-16T15:50:21.217827Z","iopub.status.idle":"2025-03-16T15:50:21.301135Z","shell.execute_reply.started":"2025-03-16T15:50:21.217792Z","shell.execute_reply":"2025-03-16T15:50:21.300109Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Max length target (ASL Gloss): 57\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"input_words = sorted(list(all_eng_words))  # English as input\ntarget_words = sorted(list(all_ASL_words))  # ASL Gloss as output\n\n# Calculate vocab size for both source (English) and target (ASL Gloss)\nnum_encoder_tokens = len(all_eng_words) + 1  # English vocab size\nnum_decoder_tokens = len(all_ASL_words) + 1  # ASL Gloss vocab size\n\nnum_encoder_tokens, num_decoder_tokens\n","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:22.829101Z","iopub.execute_input":"2025-03-16T15:50:22.829938Z","iopub.status.idle":"2025-03-16T15:50:22.854296Z","shell.execute_reply.started":"2025-03-16T15:50:22.829898Z","shell.execute_reply":"2025-03-16T15:50:22.853363Z"},"trusted":true},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"(20583, 15111)"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"# Add 1 for zero padding in both encoder (English) and decoder (ASL Gloss)\nnum_encoder_tokens += 1  # Padding for English input\nnum_decoder_tokens += 1  # Padding for ASL Gloss output\n\nnum_encoder_tokens, num_decoder_tokens\n","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:27.464244Z","iopub.execute_input":"2025-03-16T15:50:27.465265Z","iopub.status.idle":"2025-03-16T15:50:27.471021Z","shell.execute_reply.started":"2025-03-16T15:50:27.465227Z","shell.execute_reply":"2025-03-16T15:50:27.470134Z"},"trusted":true},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"(20584, 15112)"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"# Create word to token dictionary for both source and target\ninput_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n\n# Create token to word dictionary for both source and target\nreverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:29.789310Z","iopub.execute_input":"2025-03-16T15:50:29.789646Z","iopub.status.idle":"2025-03-16T15:50:29.818935Z","shell.execute_reply.started":"2025-03-16T15:50:29.789616Z","shell.execute_reply":"2025-03-16T15:50:29.818006Z"},"trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def write_list_to_file(var_list):\n    outputFile = open( \"myVars.txt\", \"w\")\n    outputFile.write(str(var_list))\n    outputFile.flush()\n    outputFile.close()\n\nvar_list = [max_length_src, max_length_tar, num_encoder_tokens, num_decoder_tokens, input_token_index, target_token_index, reverse_target_char_index]\nwrite_list_to_file(var_list)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:32.340474Z","iopub.execute_input":"2025-03-16T15:50:32.340812Z","iopub.status.idle":"2025-03-16T15:50:32.362694Z","shell.execute_reply.started":"2025-03-16T15:50:32.340784Z","shell.execute_reply":"2025-03-16T15:50:32.361745Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"code","source":"shuffle(df).head(10)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:40:30.311569Z","iopub.execute_input":"2025-03-16T15:40:30.312453Z","iopub.status.idle":"2025-03-16T15:40:30.334020Z","shell.execute_reply.started":"2025-03-16T15:40:30.312419Z","shell.execute_reply":"2025-03-16T15:40:30.333190Z"},"trusted":true},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                                                   gloss  \\\n25558  START_ descvoluntarily xwe have take xit upon ...   \n58890  START_ this will aid integration in case futur...   \n32446  START_ descre be no revolution descn descjust ...   \n39883  START_ increase in temperature will descconsid...   \n4214   START_ address generalise lack information be ...   \n27521  START_ for rest xi believe that descre be cons...   \n19310  START_ xi would like to take this opportunity ...   \n85066  START_ descso as xyou see xwe be act on descse...   \n30849  START_ consumer descoften pay for service se c...   \n59625  START_ descn descre will be no need for quota ...   \n\n                                                    text  \n25558  voluntarily  we have taken it upon ourselves t...  \n58890  this will aid integration in case of future eu...  \n32446  there is no revolution then  just some clarifi...  \n39883  the increase in temperature will considerably ...  \n4214   addressing the generalised lack of information...  \n27521  for the rest  i believe that there is a consen...  \n19310  i would like to take this opportunity to urge ...  \n85066   so  as you see  we are acting on several fronts   \n30849  consumers often pay for the services of these ...  \n59625             then there will be no need for quotas   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gloss</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25558</th>\n      <td>START_ descvoluntarily xwe have take xit upon ...</td>\n      <td>voluntarily  we have taken it upon ourselves t...</td>\n    </tr>\n    <tr>\n      <th>58890</th>\n      <td>START_ this will aid integration in case futur...</td>\n      <td>this will aid integration in case of future eu...</td>\n    </tr>\n    <tr>\n      <th>32446</th>\n      <td>START_ descre be no revolution descn descjust ...</td>\n      <td>there is no revolution then  just some clarifi...</td>\n    </tr>\n    <tr>\n      <th>39883</th>\n      <td>START_ increase in temperature will descconsid...</td>\n      <td>the increase in temperature will considerably ...</td>\n    </tr>\n    <tr>\n      <th>4214</th>\n      <td>START_ address generalise lack information be ...</td>\n      <td>addressing the generalised lack of information...</td>\n    </tr>\n    <tr>\n      <th>27521</th>\n      <td>START_ for rest xi believe that descre be cons...</td>\n      <td>for the rest  i believe that there is a consen...</td>\n    </tr>\n    <tr>\n      <th>19310</th>\n      <td>START_ xi would like to take this opportunity ...</td>\n      <td>i would like to take this opportunity to urge ...</td>\n    </tr>\n    <tr>\n      <th>85066</th>\n      <td>START_ descso as xyou see xwe be act on descse...</td>\n      <td>so  as you see  we are acting on several fronts</td>\n    </tr>\n    <tr>\n      <th>30849</th>\n      <td>START_ consumer descoften pay for service se c...</td>\n      <td>consumers often pay for the services of these ...</td>\n    </tr>\n    <tr>\n      <th>59625</th>\n      <td>START_ descn descre will be no need for quota ...</td>\n      <td>then there will be no need for quotas</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"Make a 90–10 train and test split and write a Python generator function to load the data in batches as follows:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:44.268262Z","iopub.execute_input":"2025-03-16T15:50:44.268612Z","iopub.status.idle":"2025-03-16T15:50:44.273431Z","shell.execute_reply.started":"2025-03-16T15:50:44.268582Z","shell.execute_reply":"2025-03-16T15:50:44.272452Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# Train - Test Split\nX, y = df['text'], df['gloss']  # English as input (X), ASL Gloss as output (y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:50:47.512187Z","iopub.execute_input":"2025-03-16T15:50:47.512520Z","iopub.status.idle":"2025-03-16T15:50:47.539688Z","shell.execute_reply.started":"2025-03-16T15:50:47.512491Z","shell.execute_reply":"2025-03-16T15:50:47.538776Z"},"trusted":true},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"((78939,), (8771,))"},"metadata":{}}],"execution_count":72},{"cell_type":"markdown","source":"Save the train and test dataframes for reproducing the results later, as they are shuffled.","metadata":{}},{"cell_type":"code","source":"#X_train.to_pickle('Weights_ASL/X_train.pkl')\n#X_test.to_pickle('Weights_ASL/X_test.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:57:38.472352Z","iopub.execute_input":"2023-03-08T10:57:38.472639Z","iopub.status.idle":"2023-03-08T10:57:38.4778Z","shell.execute_reply.started":"2023-03-08T10:57:38.472615Z","shell.execute_reply":"2023-03-08T10:57:38.476721Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef generate_batch(X=X_train, y=y_train, batch_size=128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            current_batch_size = min(batch_size, len(X) - j)  # Adjust for the last batch\n            \n            encoder_input_data = np.zeros((current_batch_size, max_length_src), dtype='float32')\n            decoder_input_data = np.zeros((current_batch_size, max_length_tar), dtype='float32')\n            decoder_target_data = np.zeros((current_batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n\n            for i, (input_text, target_text) in enumerate(zip(X.iloc[j:j+current_batch_size], y.iloc[j:j+current_batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index.get(word, 0)  # Handle unknown words\n\n                for t, word in enumerate(target_text.split()):\n                    if t < len(target_text.split()) - 1:\n                        decoder_input_data[i, t] = target_token_index.get(word, 0)  # Handle unknown words\n                    if 0 < t < max_length_tar:  # Ensure valid indexing\n                        decoder_target_data[i, t - 1, target_token_index.get(word, 0)] = 1.  # One-hot encoding\n\n            yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:57:16.861779Z","iopub.execute_input":"2025-03-16T15:57:16.862112Z","iopub.status.idle":"2025-03-16T15:57:16.870668Z","shell.execute_reply.started":"2025-03-16T15:57:16.862085Z","shell.execute_reply":"2025-03-16T15:57:16.869706Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"Encoder - Decoder Model Architecture","metadata":{}},{"cell_type":"code","source":"latent_dim = 50","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:57:20.257364Z","iopub.execute_input":"2025-03-16T15:57:20.257696Z","iopub.status.idle":"2025-03-16T15:57:20.261733Z","shell.execute_reply.started":"2025-03-16T15:57:20.257669Z","shell.execute_reply":"2025-03-16T15:57:20.260814Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:57:57.861827Z","iopub.execute_input":"2025-03-16T15:57:57.862152Z","iopub.status.idle":"2025-03-16T15:58:01.946090Z","shell.execute_reply.started":"2025-03-16T15:57:57.862128Z","shell.execute_reply":"2025-03-16T15:58:01.945354Z"},"trusted":true},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n\n# Use a softmax to generate a probability distribution over the target vocabulary for each time step\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:58:57.801692Z","iopub.execute_input":"2025-03-16T15:58:57.802586Z","iopub.status.idle":"2025-03-16T15:58:58.511022Z","shell.execute_reply.started":"2025-03-16T15:58:57.802552Z","shell.execute_reply":"2025-03-16T15:58:58.510190Z"},"trusted":true},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2025-03-16T15:59:05.473525Z","iopub.execute_input":"2025-03-16T15:59:05.474248Z","iopub.status.idle":"2025-03-16T15:59:05.480339Z","shell.execute_reply.started":"2025-03-16T15:59:05.474212Z","shell.execute_reply":"2025-03-16T15:59:05.479377Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 50)     1029200     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 50)     755600      input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n                                                                 lstm[0][1]                       \n                                                                 lstm[0][2]                       \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 15112)  770712      lstm_1[0][0]                     \n==================================================================================================\nTotal params: 2,595,912\nTrainable params: 2,595,912\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])","metadata":{"execution":{"iopub.status.busy":"2025-03-16T16:01:52.054029Z","iopub.execute_input":"2025-03-16T16:01:52.054726Z","iopub.status.idle":"2025-03-16T16:01:52.354013Z","shell.execute_reply.started":"2025-03-16T16:01:52.054683Z","shell.execute_reply":"2025-03-16T16:01:52.353069Z"},"trusted":true},"outputs":[],"execution_count":79},{"cell_type":"code","source":"from keras import callbacks\nearlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n                                        mode=\"min\", patience=5,\n                                        restore_best_weights=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T16:02:29.920089Z","iopub.execute_input":"2025-03-16T16:02:29.920431Z","iopub.status.idle":"2025-03-16T16:02:29.926328Z","shell.execute_reply.started":"2025-03-16T16:02:29.920404Z","shell.execute_reply":"2025-03-16T16:02:29.925283Z"},"trusted":true},"outputs":[],"execution_count":80},{"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 30\n# epochs = 10","metadata":{"execution":{"iopub.status.busy":"2025-03-16T16:24:09.275630Z","iopub.execute_input":"2025-03-16T16:24:09.276672Z","iopub.status.idle":"2025-03-16T16:24:09.280690Z","shell.execute_reply.started":"2025-03-16T16:24:09.276636Z","shell.execute_reply":"2025-03-16T16:24:09.279847Z"},"trusted":true},"outputs":[],"execution_count":84},{"cell_type":"code","source":"model.fit(generate_batch(X_test, y_test, batch_size = batch_size),\n            batch_size = batch_size,\n            steps_per_epoch = train_samples//batch_size,\n            epochs=epochs,\n            validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n            validation_steps = val_samples//batch_size, callbacks=[earlystopping])","metadata":{"execution":{"iopub.status.busy":"2025-03-16T16:24:12.737253Z","iopub.execute_input":"2025-03-16T16:24:12.737563Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/30\n616/616 [==============================] - 492s 799ms/step - loss: 0.9334 - accuracy: 0.0000e+00 - precision: 0.8961 - recall: 0.1403 - val_loss: 0.8940 - val_accuracy: 0.0000e+00 - val_precision: 0.9261 - val_recall: 0.1520\nEpoch 2/30\n616/616 [==============================] - 490s 796ms/step - loss: 0.8652 - accuracy: 0.0000e+00 - precision: 0.9017 - recall: 0.1772 - val_loss: 0.8310 - val_accuracy: 0.0000e+00 - val_precision: 0.8955 - val_recall: 0.2052\nEpoch 3/30\n616/616 [==============================] - 490s 796ms/step - loss: 0.8074 - accuracy: 0.0000e+00 - precision: 0.9043 - recall: 0.2112 - val_loss: 0.7742 - val_accuracy: 0.0000e+00 - val_precision: 0.9172 - val_recall: 0.2275\nEpoch 4/30\n616/616 [==============================] - 490s 797ms/step - loss: 0.7563 - accuracy: 0.0000e+00 - precision: 0.9062 - recall: 0.2393 - val_loss: 0.7268 - val_accuracy: 0.0000e+00 - val_precision: 0.9048 - val_recall: 0.2575\nEpoch 5/30\n616/616 [==============================] - 491s 797ms/step - loss: 0.7098 - accuracy: 0.0000e+00 - precision: 0.9097 - recall: 0.2635 - val_loss: 0.6880 - val_accuracy: 0.0000e+00 - val_precision: 0.9191 - val_recall: 0.2700\nEpoch 6/30\n616/616 [==============================] - 492s 799ms/step - loss: 0.6671 - accuracy: 0.0000e+00 - precision: 0.9144 - recall: 0.2862 - val_loss: 0.6407 - val_accuracy: 0.0000e+00 - val_precision: 0.9151 - val_recall: 0.3051\nEpoch 7/30\n616/616 [==============================] - 489s 795ms/step - loss: 0.6277 - accuracy: 0.0000e+00 - precision: 0.9192 - recall: 0.3072 - val_loss: 0.6042 - val_accuracy: 0.0000e+00 - val_precision: 0.9267 - val_recall: 0.3218\nEpoch 8/30\n616/616 [==============================] - 492s 799ms/step - loss: 0.5912 - accuracy: 0.0000e+00 - precision: 0.9229 - recall: 0.3262 - val_loss: 0.5708 - val_accuracy: 0.0000e+00 - val_precision: 0.9383 - val_recall: 0.3245\nEpoch 9/30\n616/616 [==============================] - 491s 798ms/step - loss: 0.5570 - accuracy: 0.0000e+00 - precision: 0.9262 - recall: 0.3432 - val_loss: 0.5406 - val_accuracy: 0.0000e+00 - val_precision: 0.9061 - val_recall: 0.3600\nEpoch 10/30\n616/616 [==============================] - 491s 799ms/step - loss: 0.5252 - accuracy: 0.0000e+00 - precision: 0.9292 - recall: 0.3595 - val_loss: 0.5057 - val_accuracy: 0.0000e+00 - val_precision: 0.9369 - val_recall: 0.3647\nEpoch 11/30\n616/616 [==============================] - 490s 796ms/step - loss: 0.4955 - accuracy: 7.2836e-11 - precision: 0.9317 - recall: 0.3744 - val_loss: 0.4850 - val_accuracy: 6.5464e-10 - val_precision: 0.9167 - val_recall: 0.3832\nEpoch 12/30\n616/616 [==============================] - 490s 797ms/step - loss: 0.4678 - accuracy: 4.3690e-10 - precision: 0.9347 - recall: 0.3886 - val_loss: 0.4545 - val_accuracy: 1.3093e-09 - val_precision: 0.9181 - val_recall: 0.3995\nEpoch 13/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.4419 - accuracy: 8.0108e-10 - precision: 0.9368 - recall: 0.4022 - val_loss: 0.4253 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 0.4159\nEpoch 14/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.4180 - accuracy: 1.1641e-09 - precision: 0.9390 - recall: 0.4155 - val_loss: 0.4011 - val_accuracy: 1.9639e-09 - val_precision: 0.9424 - val_recall: 0.4270\nEpoch 15/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.3952 - accuracy: 1.5293e-09 - precision: 0.9409 - recall: 0.4287 - val_loss: 0.3855 - val_accuracy: 6.5464e-10 - val_precision: 0.9498 - val_recall: 0.4232\nEpoch 16/30\n616/616 [==============================] - 493s 800ms/step - loss: 0.3743 - accuracy: 2.0387e-09 - precision: 0.9433 - recall: 0.4420 - val_loss: 0.3584 - val_accuracy: 1.9639e-09 - val_precision: 0.9477 - val_recall: 0.4554\nEpoch 17/30\n616/616 [==============================] - 492s 799ms/step - loss: 0.3547 - accuracy: 2.9856e-09 - precision: 0.9452 - recall: 0.4555 - val_loss: 0.3420 - val_accuracy: 4.5825e-09 - val_precision: 0.9529 - val_recall: 0.4613\nEpoch 18/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.3366 - accuracy: 4.8058e-09 - precision: 0.9467 - recall: 0.4685 - val_loss: 0.3233 - val_accuracy: 5.2371e-09 - val_precision: 0.9550 - val_recall: 0.4754\nEpoch 19/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.3195 - accuracy: 8.1568e-09 - precision: 0.9486 - recall: 0.4819 - val_loss: 0.3033 - val_accuracy: 7.2011e-09 - val_precision: 0.9574 - val_recall: 0.4968\nEpoch 20/30\n616/616 [==============================] - 491s 797ms/step - loss: 0.3036 - accuracy: 1.0924e-08 - precision: 0.9508 - recall: 0.4955 - val_loss: 0.2928 - val_accuracy: 7.8557e-09 - val_precision: 0.9565 - val_recall: 0.5007\nEpoch 21/30\n616/616 [==============================] - 492s 799ms/step - loss: 0.2887 - accuracy: 1.4202e-08 - precision: 0.9528 - recall: 0.5089 - val_loss: 0.2747 - val_accuracy: 1.1129e-08 - val_precision: 0.9570 - val_recall: 0.5233\nEpoch 22/30\n616/616 [==============================] - 492s 800ms/step - loss: 0.2748 - accuracy: 1.7549e-08 - precision: 0.9544 - recall: 0.5228 - val_loss: 0.2635 - val_accuracy: 1.7021e-08 - val_precision: 0.9565 - val_recall: 0.5349\nEpoch 23/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.2617 - accuracy: 2.3380e-08 - precision: 0.9559 - recall: 0.5363 - val_loss: 0.2527 - val_accuracy: 1.3747e-08 - val_precision: 0.9632 - val_recall: 0.5424\nEpoch 24/30\n616/616 [==============================] - 493s 801ms/step - loss: 0.2496 - accuracy: 2.7816e-08 - precision: 0.9576 - recall: 0.5499 - val_loss: 0.2409 - val_accuracy: 3.2077e-08 - val_precision: 0.9564 - val_recall: 0.5613\nEpoch 25/30\n536/616 [=========================>....] - ETA: 57s - loss: 0.2387 - accuracy: 3.4993e-08 - precision: 0.9591 - recall: 0.5630","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Always remember to save the weights","metadata":{}},{"cell_type":"code","source":"model.save_weights('nmt_weights_v5.h5')\nmodel.save('model_v5.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"model.save('model_v4.h5')","metadata":{}},{"cell_type":"markdown","source":"Load the weights, if you close the application","metadata":{}},{"cell_type":"code","source":"#model.load_weights('nmt_weights_v4.h5')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:50.84008Z","iopub.execute_input":"2023-03-08T11:04:50.840468Z","iopub.status.idle":"2023-03-08T11:04:50.845654Z","shell.execute_reply.started":"2023-03-08T11:04:50.840414Z","shell.execute_reply":"2023-03-08T11:04:50.844708Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Inference Setup","metadata":{}},{"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:50.84718Z","iopub.execute_input":"2023-03-08T11:04:50.848122Z","iopub.status.idle":"2023-03-08T11:04:51.768619Z","shell.execute_reply.started":"2023-03-08T11:04:50.848088Z","shell.execute_reply":"2023-03-08T11:04:51.767653Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Finally, we generate the output sequence by invoking the above setup in a loop as follows\n\nDecode sample sequeces","metadata":{}},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:51.770232Z","iopub.execute_input":"2023-03-08T11:04:51.770609Z","iopub.status.idle":"2023-03-08T11:04:51.77887Z","shell.execute_reply.started":"2023-03-08T11:04:51.770573Z","shell.execute_reply":"2023-03-08T11:04:51.777873Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Evaluation on Train Dataset","metadata":{}},{"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1\n\nk+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input ASL sentence:', X_train.iloc[k:k+1].values[0])\nprint('Actual English Translation:', y_train.iloc[k:k+1].values[0][6:-4])\nprint('Predicted English Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:51.780623Z","iopub.execute_input":"2023-03-08T11:04:51.78098Z","iopub.status.idle":"2023-03-08T11:04:54.234537Z","shell.execute_reply.started":"2023-03-08T11:04:51.780943Z","shell.execute_reply":"2023-03-08T11:04:54.233576Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"asl_sentence = []\ntrue_eng_trans = []\npred_eng_trans = []\n\nfor i in range(10):\n    k+=1\n    (input_seq, actual_output), _ = next(train_gen)\n    decoded_sentence = decode_sequence(input_seq)\n    asl_sentence.append(X_train.iloc[k:k+1].values[0])\n    true_eng_trans.append(y_train.iloc[k:k+1].values[0][6:-4])\n    pred_eng_trans.append(decoded_sentence[:-4])\n\nfor i in range(10):\n    print('Input ASL sentence:', asl_sentence[i])\n    print('Actual English Translation:', true_eng_trans[i])\n    print('Predicted English Translation:', pred_eng_trans[i])\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:54.236117Z","iopub.execute_input":"2023-03-08T11:04:54.236478Z","iopub.status.idle":"2023-03-08T11:04:57.178751Z","shell.execute_reply.started":"2023-03-08T11:04:54.23644Z","shell.execute_reply":"2023-03-08T11:04:57.177807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_sentence(sentence):\n    # lower case to standardize the sentence and remove extra spaces\n    sentence = sentence.lower().strip()\n    # if QM-wig or 6 Ws or How is in the sentence, then it is a question\n    words = ['who', 'what', 'when', 'where', 'why', 'how']\n    question_flag = 0\n    if 'qm-wig' in sentence or any(word in sentence for word in words):\n        question_flag = 1\n    sentence = sentence.replace('qm-wig', '')\n\n    # remove punctuation (isn't required but im still including it)\n    sentence = re.sub(r\"([?.!,])\", \"\", sentence)\n    # replace numbers with words\n    number_replacements = {'1': \" one \", '2':\" two \", '3':\" three \", '4':\" four \", \n                           '5':\" five \", '6':\" six \", '7':\" seven \", '8':\" eight \", \n                           '9':\" nine \", '0':\" zero \"}\n    for key, value in number_replacements.items():\n        sentence = sentence.replace(key, value)\n    # remove extra spaces\n    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n    sentence = sentence.strip()\n\n    words = sentence.split()\n    result = []\n    # Empty temporary list to store single letters\n    temp = []\n    for word in words:\n        if len(word) == 1:\n            temp.append(word)\n        else:\n            # If there are any single letters in the temporary list,\n            # join them with a dash and append to the result list\n            if temp:\n                result.append('-'.join(temp))\n                temp = []\n            # Append the non-single letter word to the result list\n            result.append(word)\n    if temp:\n        result.append('-'.join(temp))\n    \n    # Save the dashed words in a list so that it can be replaced later\n    replaced_words = [match for match in result if \"-\" in match]\n    # Replace the single letters with 'XXXXX' in the result list\n    result = [\"xxxxx\" if '-' in element else element for element in result]\n    # Join the words in the result list back into a string sentence\n    sentence = ' '.join(result)\n\n    return sentence, question_flag, replaced_words","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:57.180272Z","iopub.execute_input":"2023-03-08T11:04:57.18064Z","iopub.status.idle":"2023-03-08T11:04:57.192465Z","shell.execute_reply.started":"2023-03-08T11:04:57.180605Z","shell.execute_reply":"2023-03-08T11:04:57.191483Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentences_to_test = ['CITY YOU LIVE','TODAY, YOUR LAST CLASS WHAT',\n                     'YOUR NEXT CLASS WHAT','YOUR NAME WHAT','YOU LIKE YOUR WORK',\n                     'YOU WORK WHERE','YOUR NAME WHAT','HELLO MY NAME B O B',\n                     'HOW YOU','ME BUSY BUSY BUSY','ME HAPPY SEE YOU','HOW YOUR DAY',\n                     'ALL DAY WORK ME','YOU WORK YOU DODO','SCHOOL ME WORK']\nsentences_translation = []\nsentences_counter = 0","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:57.193954Z","iopub.execute_input":"2023-03-08T11:04:57.194345Z","iopub.status.idle":"2023-03-08T11:04:57.206485Z","shell.execute_reply.started":"2023-03-08T11:04:57.194311Z","shell.execute_reply":"2023-03-08T11:04:57.205624Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\nimport numpy as np\nimport time\nimport ast\n\nclass colors:\n    RED_BOLD = '\\033[91m' + '\\033[1m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    UNDERLINE = '\\033[4m'\n    UNDERLINE_GREEN = '\\033[4m' + '\\033[92m'\n\ndef read_list_from_file():\n    inputFile = open( \"/kaggle/working/myVars.txt\", \"r\")\n    lines = inputFile.readlines()\n\n    objects = []\n    for line in lines:\n        objects.append(ast.literal_eval(line))\n    \n    return objects[0][0], objects[0][1], objects[0][2], objects[0][3], objects[0][4], objects[0][5], objects[0][6]\n\n# get the start time\nst_final = time.time()\nst = time.time()\n\nmax_length_src, max_length_tar, num_encoder_tokens, num_decoder_tokens, input_token_index, target_token_index, reverse_target_char_index = read_list_from_file()\n\nprint(colors.UNDERLINE_GREEN + 'Importing Variables:' + colors.ENDC, round(time.time() - st, 2), 'seconds')\nst = time.time()\n\nlatent_dim = 50\n\n# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\n'''\nWe set up our decoder to return full output sequences, and to return internal states as well. \nWe don't use the return states in the training model, but we will use them in inference.\n'''\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n# Define the model that will turn `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\nprint(colors.UNDERLINE_GREEN + 'Setting up Model:' + colors.ENDC, round(time.time() - st, 2), 'seconds')\nst = time.time()\n\nmodel.load_weights('/kaggle/working/nmt_weights_v5.h5')\n\nprint(colors.UNDERLINE_GREEN + 'Loading Weights:' + colors.ENDC, round(time.time() - st, 2), 'seconds')\nst = time.time()\n\n### INFERENCING ###\nencoder_model = Model(encoder_inputs, encoder_states) # Encode the input sequence to get the \"thought vectors\"\n\n# Decoder setup - Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n\nprint(colors.UNDERLINE_GREEN + 'Setting up Decoder:' + colors.ENDC, round(time.time() - st, 2), 'seconds')\nst = time.time()\n\n# Reverse-lookup token index to decode sequences back to something readable.\ndef decode_sequence(input_text):\n    encoder_input_data = np.zeros((1, max_length_src), dtype='float32')\n    error_word = ''\n    try:\n        for i, input_text in enumerate([input_text]):\n            #print(colors.WARNING + \"i:\", i, \" | input_text: \", input_text, \"\" + colors.ENDC)\n            for t, word in enumerate(input_text.split()):\n                error_word = word\n                encoder_input_data[i, t] = input_token_index[word]\n    except:\n        return colors.RED_BOLD + '\"' + error_word + '\" doesn\\'t exist in the dataset.' + colors.ENDC\n    \n    states_value = encoder_model.predict(encoder_input_data)\n    \n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = target_token_index['START_']\n    stop_condition = False\n    decoded_sentence = ''\n\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' ' + sampled_char\n        \n        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n            stop_condition = True\n        \n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n        states_value = [h, c]\n    \n    return decoded_sentence[:-4]\n\ndef preprocess_sentence(sentence):\n    # lower case to standardize the sentence and remove extra spaces\n    sentence = sentence.lower().strip()\n    # if QM-wig or 6 Ws or How is in the sentence, then it is a question\n    words = ['who', 'what', 'when', 'where', 'why', 'how']\n    question_flag = 0\n    if 'qm-wig' in sentence or any(word in sentence for word in words):\n        question_flag = 1\n    sentence = sentence.replace('qm-wig', '')\n\n    # remove punctuation (isn't required but im still including it)\n    sentence = re.sub(r\"([?.!,])\", \"\", sentence)\n    # replace numbers with words\n    number_replacements = {'1': \" one \", '2':\" two \", '3':\" three \", '4':\" four \", \n                           '5':\" five \", '6':\" six \", '7':\" seven \", '8':\" eight \", \n                           '9':\" nine \", '0':\" zero \"}\n    for key, value in number_replacements.items():\n        sentence = sentence.replace(key, value)\n    # remove extra spaces\n    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n    sentence = sentence.strip()\n\n    words = sentence.split()\n    result = []\n    # Empty temporary list to store single letters\n    temp = []\n    for word in words:\n        if len(word) == 1:\n            temp.append(word)\n        else:\n            # If there are any single letters in the temporary list,\n            # join them with a dash and append to the result list\n            if temp:\n                result.append('-'.join(temp))\n                temp = []\n            # Append the non-single letter word to the result list\n            result.append(word)\n    if temp:\n        result.append('-'.join(temp))\n    \n    # Save the dashed words in a list so that it can be replaced later\n    replaced_words = [match for match in result if \"-\" in match]\n    # Replace the single letters with 'XXXXX' in the result list\n    result = [\"xxxxx\" if '-' in element else element for element in result]\n    # Join the words in the result list back into a string sentence\n    sentence = ' '.join(result)\n\n    return sentence, question_flag, replaced_words\n\nsentences_to_test = ['CITY YOU LIVE','TODAY, YOUR LAST CLASS WHAT',\n                     'YOUR NEXT CLASS WHAT','YOUR NAME WHAT','YOU LIKE YOUR WORK',\n                     'YOU WORK WHERE','YOUR NAME WHAT','HELLO MY NAME B O B',\n                     'HOW YOU','ME BUSY BUSY BUSY','ME HAPPY SEE YOU','HOW YOUR DAY',\n                     'ALL DAY WORK ME','YOU WORK YOU DODO','SCHOOL ME WORK']\nsentences_translation = []\nsentences_counter = 0\n\nwhile sentences_counter < len(sentences_to_test):\n    #input_text = input(colors.WARNING + 'Input ASL sentence: ' + colors.ENDC)\n    #prep_input, question_flag, replaced_words = preprocess_sentence(input_text)\n    prep_input, question_flag, replaced_words = preprocess_sentence(sentences_to_test[sentences_counter])\n    if prep_input == 'exit':\n        break\n    \n    # if only 1 word is given, then no need to decode\n    decoded_sentence = decode_sequence(prep_input) if len(prep_input.split()) > 1 else prep_input\n\n    # if '?' not in decoded sentence and original input had 'QM-wig' then add '?' at the end\n    if '?' not in decoded_sentence and question_flag == 1:\n        decoded_sentence = decoded_sentence.strip() + '?'\n\n    # Replace the 'XXXXX' with the original single letter words\n    for word in replaced_words:\n        decoded_sentence = decoded_sentence.replace('xxxxx', word.replace('-',''), 1)\n    decoded_sentence = decoded_sentence.replace('xxxxx', '')\n    \n    # if decoded sentence contains ['who', 'what', 'when', 'where', 'why', 'how'] then add '?' at the end\n    if any(word in decoded_sentence for word in ['who', 'what', 'when', 'where', 'why', 'how']) and '?' not in decoded_sentence:\n        decoded_sentence = decoded_sentence.strip() + '?'\n     \n    sentences_translation.append(decoded_sentence)\n    # Outputs \n    \"\"\"\n    print(colors.WARNING + '\\nInput ASL sentence:' + colors.ENDC + \"'\" + input_text + \"'\")\n    print(colors.WARNING + 'Preprocessed Input:' + colors.ENDC + \"'\" + prep_input + \"'\")\n    print(colors.WARNING + 'Predicted English Translation:' + colors.ENDC, decoded_sentence)\n    print(colors.UNDERLINE_GREEN + 'Decoding Sequence:' + colors.ENDC, round(time.time() - st, 2), 'seconds')\n    \"\"\"\n    sentences_counter += 1\n\n# Print sentences to test and their translations\n\nfor i, sentence in enumerate(sentences_to_test):\n    print(colors.WARNING + 'Input ASL sentence:' + colors.ENDC + \"'\" + sentence + \"'\")\n    print(colors.WARNING + 'Predicted English Translation:' + colors.ENDC, sentences_translation[i])\n    print()\n\nprint(colors.UNDERLINE_GREEN + 'Total Execution time:' + colors.ENDC, round(time.time() - st_final, 2), 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T11:04:57.208219Z","iopub.execute_input":"2023-03-08T11:04:57.208639Z","iopub.status.idle":"2023-03-08T11:05:05.923103Z","shell.execute_reply.started":"2023-03-08T11:04:57.208603Z","shell.execute_reply":"2023-03-08T11:05:05.922101Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}